{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138315f9-623d-4f36-8738-ea4113ce0e7b",
   "metadata": {},
   "source": [
    "# CS 584 Final Project \n",
    "# DETECTING DISCUSSION TOPICS AND SENTIMENT IN REDDIT THREADS <br>\n",
    "\n",
    "\n",
    "#### Name: Uros Nikolic and Sam Preston\n",
    "#### Stevens ID: 20017063, 10463953"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fb530bc-ab7d-4acf-a888-ba1d214d4bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pa\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import evaluate\n",
    "from textblob import TextBlob\n",
    "from torchinfo import summary\n",
    "from typing import List, Tuple, Union, Dict\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1c7ff3c-8975-4762-904c-8626207cd066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_line(*args):\n",
    "    \"\"\" Inline print and go to the begining of line\n",
    "    \"\"\"\n",
    "    args1 = [str(arg) for arg in args]\n",
    "    str_ = ' '.join(args1)\n",
    "    print('\\r' + str_, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da081479-a6e2-4475-ba4b-ca09c0343f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important pip commands for installing some of the neccesasry libraries. \n",
    "\n",
    "#!pip install torch\n",
    "#!pip uninstall torch torchvision torchaudio\n",
    "\n",
    "#!pip install -U datasets\n",
    "\n",
    "#!pip install tokenizers\n",
    "\n",
    "#!pip install torchinfo\n",
    "\n",
    "#!pip install evaluate\n",
    "#!pip install sacrebleu\n",
    "\n",
    "#!pip install textblob\n",
    "#python -m textblob.download_corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b806ed1-331c-4276-aaf5-10a2b59f19d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Testing the Cuda cores on personal machine\n",
    "print(torch.cuda.is_available())           \n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a09c6f5-5c3c-4a16-9e21-5a7aa8b6112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data extratcion\n",
    "\n",
    "controversialPosts = pa.read_csv('data/controversial_posts.csv')\n",
    "controversialPostComments = pa.read_csv('data/controversial_posts_comments.csv')\n",
    "hotPost = pa.read_csv('data/hot_posts.csv')\n",
    "hotPostComments = pa.read_csv('data/hot_post_comments.csv')\n",
    "newPost = pa.read_csv('data/new_posts.csv')\n",
    "newPostComments = pa.read_csv('data/new_post_comments.csv')\n",
    "topPost = pa.read_csv('data/top_posts.csv')\n",
    "topPostComments = pa.read_csv('data/top_posts_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c469e0d8-eb6b-431c-88d6-a00e58c603f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(df, post=True):\n",
    "    if post:\n",
    "        df['body']  = df.get('body','').fillna('')\n",
    "        df['title'] = df.get('title','').fillna('')\n",
    "        df['text']  = (df['title'].str.strip() + ' ' + df['body'].str.strip()).str.strip()\n",
    "    else:\n",
    "        df['body'] = df.get('body', df.get('comment','')).fillna('')\n",
    "        df['text'] = df['body'].str.strip()\n",
    "    return df[df['text']!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54ff147e-61bf-4962-8ea8-535c523d5bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3792 posts, 113310 comments.\n",
      "Loaded 0        11\n",
      "1         0\n",
      "2         0\n",
      "3       303\n",
      "4         0\n",
      "       ... \n",
      "3787    820\n",
      "3788    821\n",
      "3789    825\n",
      "3790    824\n",
      "3791    817\n",
      "Name: score, Length: 3792, dtype: int64 posts.\n"
     ]
    }
   ],
   "source": [
    "posts = pa.concat([\n",
    "    extract_text(controversialPosts, post=True),\n",
    "    extract_text(hotPost,         post=True),\n",
    "    extract_text(newPost,         post=True),\n",
    "    extract_text(topPost,         post=True),\n",
    "], ignore_index=True)\n",
    "\n",
    "comments = pa.concat([\n",
    "    extract_text(controversialPostComments, post=False),\n",
    "    extract_text(hotPostComments,           post=False),\n",
    "    extract_text(newPostComments,           post=False),\n",
    "    extract_text(topPostComments,           post=False),\n",
    "], ignore_index=True)\n",
    "\n",
    "print(f\"Loaded {len(posts)} posts, {len(comments)} comments.\")\n",
    "print(f\"Loaded {posts[\"score\"]} posts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5fbf312-7035-4483-a929-2c340d70104e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment distribution:\n",
      " sentiment\n",
      "1    0.7564\n",
      "0    0.2436\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 3) COMBINE POSTS+COMMENTS & DERIVE SENTIMENT VIA TEXTBLOB\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "data = pa.concat([\n",
    "    posts   [['text']],\n",
    "    comments[['text']]\n",
    "], ignore_index=True)\n",
    "\n",
    "# compute polarity ∈ [−1,1], then binarize:\n",
    "data['polarity'] = data['text'].apply(lambda t: TextBlob(t).sentiment.polarity)\n",
    "data['sentiment'] = (data['polarity'] >= 0).astype(int)\n",
    "\n",
    "print(\"Sentiment distribution:\\n\", data['sentiment'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7983643-744d-4e35-9cbf-724a95de290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Body\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 4) TF-IDF + TRAIN/TEST SPLIT\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "X = data['text']\n",
    "y = data['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf  = tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d1941c-6380-4342-97b3-455e8e99ea57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training LogisticRegression\n",
      "Acc=0.905  Prec=0.909  Rec=0.972  F1=0.939\n",
      "\n",
      ">>> Training NaiveBayes\n",
      "Acc=0.841  Prec=0.831  Rec=0.991  F1=0.904\n",
      "\n",
      ">>> Training LinearSVM\n",
      "Acc=0.919  Prec=0.931  Rec=0.965  F1=0.948\n",
      "\n",
      ">>> Training RandomForest\n",
      "Acc=0.927  Prec=0.951  Rec=0.953  F1=0.952\n",
      "\n",
      ">>> Training MLP\n",
      "Acc=0.936  Prec=0.948  Rec=0.968  F1=0.958\n",
      "\n",
      "Summary:\n",
      "                 Model  Accuracy  Precision    Recall        F1\n",
      "0  LogisticRegression  0.904914   0.909004  0.971551  0.939238\n",
      "1          NaiveBayes  0.840613   0.830990  0.990799  0.903885\n",
      "2           LinearSVM  0.919303   0.930569  0.965342  0.947637\n",
      "3        RandomForest  0.926775   0.950707  0.952585  0.951645\n",
      "4                 MLP  0.935571   0.947534  0.968447  0.957876\n",
      "\n",
      "Detailed report for MLP:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86      5705\n",
      "           1       0.95      0.97      0.96     17716\n",
      "\n",
      "    accuracy                           0.94     23421\n",
      "   macro avg       0.92      0.90      0.91     23421\n",
      "weighted avg       0.93      0.94      0.93     23421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression for multi-class topic classification\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'NaiveBayes':         MultinomialNB(),\n",
    "    'LinearSVM':          LinearSVC(max_iter=2000, random_state=42),\n",
    "    'RandomForest':       RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'MLP':                MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42),\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\n>>> Training {name}\")\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    acc   = accuracy_score(y_test, y_pred)\n",
    "    prec  = precision_score(y_test, y_pred)\n",
    "    rec   = recall_score(y_test, y_pred)\n",
    "    f1    = f1_score(y_test, y_pred)\n",
    "    print(f\"Acc={acc:.3f}  Prec={prec:.3f}  Rec={rec:.3f}  F1={f1:.3f}\")\n",
    "    results.append((name, acc, prec, rec, f1))\n",
    "\n",
    "res_df = pa.DataFrame(results, columns=['Model','Accuracy','Precision','Recall','F1'])\n",
    "print(\"\\nSummary:\\n\", res_df)\n",
    "\n",
    "best = res_df.sort_values('F1', ascending=False).iloc[0]['Model']\n",
    "print(f\"\\nDetailed report for {best}:\\n\")\n",
    "print(classification_report(y_test, models[best].predict(X_test_tfidf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f21c6693-0fae-43d7-bc18-059467236e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c96f3d5-a2a2-4070-8ba0-f506be25e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
