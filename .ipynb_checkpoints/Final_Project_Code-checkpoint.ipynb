{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138315f9-623d-4f36-8738-ea4113ce0e7b",
   "metadata": {},
   "source": [
    "# CS 584 Final Project \n",
    "# DETECTING DISCUSSION TOPICS AND SENTIMENT IN REDDIT THREADS <br>\n",
    "\n",
    "\n",
    "#### Name: Uros Nikolic and Sam Preston\n",
    "#### Stevens ID: 20017063,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fb530bc-ab7d-4acf-a888-ba1d214d4bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pa\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import evaluate\n",
    "from torchinfo import summary\n",
    "from typing import List, Tuple, Union, Dict\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1c7ff3c-8975-4762-904c-8626207cd066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_line(*args):\n",
    "    \"\"\" Inline print and go to the begining of line\n",
    "    \"\"\"\n",
    "    args1 = [str(arg) for arg in args]\n",
    "    str_ = ' '.join(args1)\n",
    "    print('\\r' + str_, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da081479-a6e2-4475-ba4b-ca09c0343f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important pip commands for installing some of the neccesasry libraries. \n",
    "\n",
    "#!pip install torch\n",
    "#!pip uninstall torch torchvision torchaudio\n",
    "\n",
    "#!pip install -U datasets\n",
    "\n",
    "#!pip install tokenizers\n",
    "\n",
    "#!pip install torchinfo\n",
    "\n",
    "#!pip install evaluate\n",
    "#!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b806ed1-331c-4276-aaf5-10a2b59f19d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Testing the Cuda cores on personal machine\n",
    "print(torch.cuda.is_available())           \n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1331dc1c-2314-4be2-8cf5-e6404fd25352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subreddit\n",
      "RussiaUkraineWar2022    3792\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data extratcion\n",
    "\n",
    "controversialPosts = pa.read_csv('data/controversial_posts.csv')\n",
    "controversialPostComments = pa.read_csv('data/controversial_posts_comments.csv')\n",
    "hotPost = pa.read_csv('data/hot_posts.csv')\n",
    "hotPostComments = pa.read_csv('data/hot_posts_comments.csv')\n",
    "newPost = pa.read_csv('data/new_posts.csv')\n",
    "newPostComments = pa.read_csv('data/new_posts_comments.csv')\n",
    "topPost = pa.read_csv('data/top_posts.csv')\n",
    "topPostComments = pa.read_csv('data/top_posts_comments.csv')\n",
    "\n",
    "\n",
    "posts_df = pa.concat([controversial, hot, new, top], ignore_index=True)\n",
    "\n",
    "posts_df = posts_df[['title', 'body', 'subreddit']].fillna('')\n",
    "posts_df['text'] = posts_df['title'] + ' ' + posts_df['body']\n",
    "posts_df = posts_df[['text', 'subreddit']]\n",
    "\n",
    "posts_df = posts_df[posts_df['subreddit'].notna()]\n",
    "posts_df = posts_df[posts_df['text'].str.strip() != '']\n",
    "print(posts_df['subreddit'].value_counts().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7983643-744d-4e35-9cbf-724a95de290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Body\n",
    "\n",
    "X = posts_df['text']\n",
    "y = posts_df['subreddit'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40d1941c-6380-4342-97b3-455e8e99ea57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derived topics in train: [0 1 2 3 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78       208\n",
      "           1       0.82      0.55      0.66       109\n",
      "           2       0.83      0.93      0.88       302\n",
      "           3       0.88      0.69      0.77        84\n",
      "           4       0.96      0.39      0.56        56\n",
      "\n",
      "    accuracy                           0.80       759\n",
      "   macro avg       0.84      0.69      0.73       759\n",
      "weighted avg       0.81      0.80      0.79       759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression for multi-class topic classification\n",
    "\n",
    "cv = CountVectorizer(max_features=5_000, stop_words='english')\n",
    "X_train_counts = cv.fit_transform(X_train)\n",
    "X_test_counts  = cv.transform(X_test)\n",
    "\n",
    "K = 5\n",
    "lda = LatentDirichletAllocation(n_components=K, random_state=42)\n",
    "lda.fit(X_train_counts)\n",
    "\n",
    "train_topic_dist = lda.transform(X_train_counts)\n",
    "test_topic_dist  = lda.transform(X_test_counts)\n",
    "\n",
    "y_train_topics = train_topic_dist.argmax(axis=1)\n",
    "y_test_topics  = test_topic_dist.argmax(axis=1)\n",
    "\n",
    "print(\"Derived topics in train:\", np.unique(y_train_topics))\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_tfidf, y_train_topics)\n",
    "y_pred_topics = clf.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "print(classification_report(y_test_topics, y_pred_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f21c6693-0fae-43d7-bc18-059467236e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c96f3d5-a2a2-4070-8ba0-f506be25e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
