{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138315f9-623d-4f36-8738-ea4113ce0e7b",
   "metadata": {},
   "source": [
    "# CS 584 Final Project \n",
    "# DETECTING DISCUSSION TOPICS AND SENTIMENT IN REDDIT THREADS <br>\n",
    "\n",
    "\n",
    "#### Name: Uros Nikolic and Sam Preston\n",
    "#### Stevens ID: 20017063,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb530bc-ab7d-4acf-a888-ba1d214d4bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pa\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import evaluate\n",
    "from torchinfo import summary\n",
    "from typing import List, Tuple, Union, Dict\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7ff3c-8975-4762-904c-8626207cd066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_line(*args):\n",
    "    \"\"\" Inline print and go to the begining of line\n",
    "    \"\"\"\n",
    "    args1 = [str(arg) for arg in args]\n",
    "    str_ = ' '.join(args1)\n",
    "    print('\\r' + str_, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da081479-a6e2-4475-ba4b-ca09c0343f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important pip commands for installing some of the neccesasry libraries. \n",
    "\n",
    "#!pip install torch\n",
    "#!pip uninstall torch torchvision torchaudio\n",
    "\n",
    "#!pip install -U datasets\n",
    "\n",
    "#!pip install tokenizers\n",
    "\n",
    "#!pip install torchinfo\n",
    "\n",
    "#!pip install evaluate\n",
    "#!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b806ed1-331c-4276-aaf5-10a2b59f19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the Cuda cores on personal machine\n",
    "print(torch.cuda.is_available())           \n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1331dc1c-2314-4be2-8cf5-e6404fd25352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data extratcion\n",
    "\n",
    "controversialPosts = pa.read_csv('data/controversial_posts.csv')\n",
    "controversialPostComments = pa.read_csv('data/controversial_posts_comments.csv')\n",
    "hotPost = pa.read_csv('data/hot_posts.csv')\n",
    "hotPostComments = pa.read_csv('data/hot_post_comments.csv')\n",
    "newPost = pa.read_csv('data/new_posts.csv')\n",
    "newPostComments = pa.read_csv('data/new_post_comments.csv')\n",
    "topPost = pa.read_csv('data/top_posts.csv')\n",
    "topPostComments = pa.read_csv('data/top_posts_comments.csv')\n",
    "\n",
    "\n",
    "posts_df = pa.concat([controversial, hot, new, top], ignore_index=True)\n",
    "\n",
    "posts_df = posts_df[['title', 'body', 'subreddit']].fillna('')\n",
    "posts_df['text'] = posts_df['title'] + ' ' + posts_df['body']\n",
    "posts_df = posts_df[['text', 'subreddit']]\n",
    "\n",
    "posts_df = posts_df[posts_df['subreddit'].notna()]\n",
    "posts_df = posts_df[posts_df['text'].str.strip() != '']\n",
    "print(posts_df['subreddit'].value_counts().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7983643-744d-4e35-9cbf-724a95de290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Body\n",
    "\n",
    "X = posts_df['text']\n",
    "y = posts_df['subreddit'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d1941c-6380-4342-97b3-455e8e99ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression for multi-class topic classification\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"NaiveBayes\":         MultinomialNB(),\n",
    "    \"LinearSVM\":          LinearSVC(max_iter=2000, random_state=42),\n",
    "    \"RandomForest\":       RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"MLP\":                MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\n>>> Training {name}...\")\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    acc  = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec  = recall_score(y_test, y_pred)\n",
    "    f1   = f1_score(y_test, y_pred)\n",
    "    print(f\"{name} â€” Acc: {acc:.3f}, Prec: {prec:.3f}, Rec: {rec:.3f}, F1: {f1:.3f}\")\n",
    "    results.append((name, acc, prec, rec, f1))\n",
    "\n",
    "# aggregate into df\n",
    "res_df = pd.DataFrame(results, columns=[\"Model\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n",
    "print(\"\\nSummary:\\n\", res_df)\n",
    "\n",
    "# detailed report for best model\n",
    "best = res_df.sort_values(\"F1\", ascending=False).iloc[0][\"Model\"]\n",
    "print(f\"\\nDetailed classification report for {best}:\\n\")\n",
    "print(classification_report(y_test, models[best].predict(X_test_tfidf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c6693-0fae-43d7-bc18-059467236e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c96f3d5-a2a2-4070-8ba0-f506be25e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
